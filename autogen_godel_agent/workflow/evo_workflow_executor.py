"""
EvoAgentX-Style Workflow Executor

This module implements the workflow execution engine adapted from EvoAgentX,
integrating with AutoGen agents for actual task execution. It maintains the
core execution patterns while providing enhanced error handling and monitoring.

Key Features:
- Sequential and parallel execution patterns
- AutoGen agent integration
- Comprehensive error handling and recovery
- Performance monitoring and analytics
- Result validation and quality assurance
"""

import logging
import time
import asyncio
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass
from enum import Enum
from datetime import datetime

import autogen
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

try:
    from workflow.evo_core_algorithms import EvoWorkflowGraph, EvoWorkflowNode
except ImportError:
    from evo_core_algorithms import EvoWorkflowGraph, EvoWorkflowNode

logger = logging.getLogger(__name__)


class ExecutionStatus(Enum):
    """Execution status enumeration."""
    PENDING = "pending"
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"
    CANCELLED = "cancelled"


@dataclass
class NodeExecutionResult:
    """Result of executing a single workflow node."""
    node_name: str
    status: ExecutionStatus
    output: Any = None
    execution_time: float = 0.0
    error: Optional[str] = None
    agent_messages: List[Dict] = None
    
    def __post_init__(self):
        if self.agent_messages is None:
            self.agent_messages = []


@dataclass
class WorkflowExecutionResult:
    """Result of executing an entire workflow."""
    workflow_id: str
    goal: str
    status: ExecutionStatus
    final_output: Any = None
    total_execution_time: float = 0.0
    node_results: Dict[str, NodeExecutionResult] = None
    errors: List[str] = None
    metadata: Dict[str, Any] = None
    
    def __post_init__(self):
        if self.node_results is None:
            self.node_results = {}
        if self.errors is None:
            self.errors = []
        if self.metadata is None:
            self.metadata = {}


class EvoWorkflowExecutor:
    """
    EvoAgentX-style workflow executor adapted for AutoGen.
    
    This class executes workflows generated by EvoWorkflowGenerator,
    managing AutoGen agents and coordinating task execution according
    to the workflow structure.
    """
    
    def __init__(self, llm_config: Dict[str, Any]):
        self.llm_config = llm_config
        self.active_agents = {}
        self.execution_history = []
        
        logger.info("âœ… EvoWorkflowExecutor initialized")
    
    async def execute_workflow(self, workflow: EvoWorkflowGraph, 
                             initial_input: str = None) -> WorkflowExecutionResult:
        """
        Execute a workflow graph using AutoGen agents.
        
        Args:
            workflow: The EvoWorkflowGraph to execute
            initial_input: Initial input for the workflow
            
        Returns:
            WorkflowExecutionResult with execution details
        """
        start_time = time.time()
        
        logger.info(f"ðŸš€ Executing EvoAgentX workflow: {workflow.goal}")
        
        result = WorkflowExecutionResult(
            workflow_id=workflow.id,
            goal=workflow.goal,
            status=ExecutionStatus.RUNNING
        )
        
        try:
            # Step 1: Create AutoGen agents for all nodes
            await self._create_workflow_agents(workflow)
            
            # Step 2: Determine execution order
            execution_order = self._determine_execution_order(workflow)
            logger.info(f"ðŸ“‹ Execution order: {[node.name for node in execution_order]}")
            
            # Step 3: Execute nodes in order
            node_outputs = {}
            initial_data = initial_input or workflow.goal
            
            for node in execution_order:
                try:
                    logger.info(f"ðŸ“ Executing node: {node.name}")
                    
                    # Prepare input for this node
                    node_input = self._prepare_node_input(node, node_outputs, initial_data)
                    
                    # Execute the node
                    node_result = await self._execute_node(node, node_input)
                    
                    # Store result
                    result.node_results[node.name] = node_result
                    
                    if node_result.status == ExecutionStatus.COMPLETED:
                        node_outputs[node.name] = node_result.output
                        logger.info(f"âœ… Node {node.name} completed successfully")
                    else:
                        logger.error(f"âŒ Node {node.name} failed: {node_result.error}")
                        result.errors.append(f"Node {node.name} failed: {node_result.error}")
                        
                        # Decide whether to continue or abort
                        if self._should_abort_on_failure(node, workflow):
                            raise Exception(f"Critical node {node.name} failed, aborting workflow")
                    
                except Exception as e:
                    error_msg = f"Node {node.name} execution failed: {str(e)}"
                    logger.error(error_msg)
                    result.errors.append(error_msg)
                    
                    # Create failed node result
                    result.node_results[node.name] = NodeExecutionResult(
                        node_name=node.name,
                        status=ExecutionStatus.FAILED,
                        error=str(e)
                    )
                    
                    if self._should_abort_on_failure(node, workflow):
                        raise e
            
            # Step 4: Determine final output
            result.final_output = self._determine_final_output(workflow, node_outputs)
            result.status = ExecutionStatus.COMPLETED
            result.total_execution_time = time.time() - start_time
            
            logger.info(f"âœ… Workflow execution completed in {result.total_execution_time:.2f}s")
            
        except Exception as e:
            logger.error(f"âŒ Workflow execution failed: {e}")
            result.status = ExecutionStatus.FAILED
            result.total_execution_time = time.time() - start_time
            result.errors.append(f"Workflow execution failed: {str(e)}")
        
        # Record execution history
        self.execution_history.append(result)
        
        return result
    
    async def _create_workflow_agents(self, workflow: EvoWorkflowGraph):
        """Create AutoGen agents for all workflow nodes."""
        
        for node in workflow.nodes:
            try:
                if not node.agents:
                    raise ValueError(f"Node {node.name} has no agent configuration")
                
                # Use the first agent configuration
                agent_config = node.agents[0]
                
                # Create AutoGen agent
                agent = autogen.AssistantAgent(
                    name=f"{agent_config.get('name', node.name)}_{node.name}",
                    system_message=agent_config.get('system_message', f"You are responsible for: {node.description}"),
                    llm_config=self.llm_config
                )
                
                self.active_agents[node.name] = agent
                logger.debug(f"Created AutoGen agent for node: {node.name}")
                
            except Exception as e:
                logger.error(f"Failed to create agent for node {node.name}: {e}")
                raise e
    
    def _determine_execution_order(self, workflow: EvoWorkflowGraph) -> List[EvoWorkflowNode]:
        """
        Determine the execution order of nodes based on dependencies.
        
        Uses topological sorting to ensure dependencies are respected.
        """
        # Build dependency graph
        dependencies = {}
        for node in workflow.nodes:
            dependencies[node.name] = []
        
        # Add edges as dependencies
        for edge in workflow.edges:
            if edge.target in dependencies:
                dependencies[edge.target].append(edge.source)
        
        # Topological sort
        visited = set()
        temp_visited = set()
        result = []
        
        def visit(node_name: str):
            if node_name in temp_visited:
                raise ValueError(f"Circular dependency detected involving {node_name}")
            if node_name in visited:
                return
            
            temp_visited.add(node_name)
            
            for dep in dependencies.get(node_name, []):
                visit(dep)
            
            temp_visited.remove(node_name)
            visited.add(node_name)
            
            # Find the actual node object
            node = next((n for n in workflow.nodes if n.name == node_name), None)
            if node:
                result.append(node)
        
        # Visit all nodes
        for node in workflow.nodes:
            if node.name not in visited:
                visit(node.name)
        
        return result
    
    def _prepare_node_input(self, node: EvoWorkflowNode, node_outputs: Dict[str, Any], 
                          initial_data: str) -> str:
        """Prepare input for a node based on its dependencies and requirements."""
        
        # If node has no inputs defined, use initial data
        if not node.inputs:
            return initial_data
        
        # Collect inputs from previous nodes
        collected_inputs = {}
        
        for input_param in node.inputs:
            input_name = input_param.name
            
            # Look for this input in previous node outputs
            found_input = None
            for output_node_name, output_data in node_outputs.items():
                # Simple matching - look for input name in output
                if input_name in str(output_data).lower() or input_name == "requirements" or input_name == "analysis":
                    found_input = output_data
                    break
            
            if found_input is not None:
                collected_inputs[input_name] = found_input
            else:
                # Use initial data as fallback
                collected_inputs[input_name] = initial_data
        
        # Format inputs for the agent
        if collected_inputs:
            input_text = f"Task: {node.description}\n\nInputs:\n"
            for key, value in collected_inputs.items():
                input_text += f"- {key}: {value}\n"
            input_text += f"\nPlease process these inputs according to your role and produce the required outputs."
            return input_text
        else:
            return f"Task: {node.description}\n\nContext: {initial_data}\n\nPlease complete this task according to your role."
    
    async def _execute_node(self, node: EvoWorkflowNode, node_input: str) -> NodeExecutionResult:
        """Execute a single workflow node using its AutoGen agent."""
        
        start_time = time.time()
        
        try:
            # Get the agent for this node
            agent = self.active_agents[node.name]
            
            # Create user proxy for interaction
            user_proxy = autogen.UserProxyAgent(
                name=f"user_proxy_{node.name}",
                human_input_mode="NEVER",
                max_consecutive_auto_reply=1,
                code_execution_config=False
            )
            
            # Execute the task
            user_proxy.initiate_chat(
                agent,
                message=node_input
            )
            
            # Get the response
            chat_history = user_proxy.chat_messages.get(agent, [])
            
            if chat_history:
                output = chat_history[-1]["content"]
                
                return NodeExecutionResult(
                    node_name=node.name,
                    status=ExecutionStatus.COMPLETED,
                    output=output,
                    execution_time=time.time() - start_time,
                    agent_messages=chat_history
                )
            else:
                raise Exception("No response from agent")
                
        except Exception as e:
            return NodeExecutionResult(
                node_name=node.name,
                status=ExecutionStatus.FAILED,
                execution_time=time.time() - start_time,
                error=str(e)
            )
    
    def _should_abort_on_failure(self, node: EvoWorkflowNode, workflow: EvoWorkflowGraph) -> bool:
        """Determine if workflow should abort when a node fails."""
        
        # For now, abort if any node fails
        # In the future, this could be more sophisticated based on node criticality
        return True
    
    def _determine_final_output(self, workflow: EvoWorkflowGraph, 
                              node_outputs: Dict[str, Any]) -> str:
        """Determine the final output of the workflow."""
        
        # Find the last node in execution order (likely the final output)
        if not node_outputs:
            return f"Workflow completed but no outputs were generated for goal: {workflow.goal}"
        
        # Get the output from the last executed node
        last_output = list(node_outputs.values())[-1]
        
        # Format final result
        final_result = f"Workflow Goal: {workflow.goal}\n\n"
        final_result += f"Final Result: {last_output}\n\n"
        final_result += f"Generated through {len(node_outputs)} workflow steps:\n"
        
        for i, (node_name, output) in enumerate(node_outputs.items(), 1):
            final_result += f"{i}. {node_name}: {str(output)[:100]}{'...' if len(str(output)) > 100 else ''}\n"
        
        return final_result
    
    def get_execution_analytics(self) -> Dict[str, Any]:
        """Get analytics about workflow execution performance."""
        
        if not self.execution_history:
            return {
                "total_executions": 0,
                "success_rate": 0,
                "average_execution_time": 0
            }
        
        total = len(self.execution_history)
        successful = sum(1 for r in self.execution_history if r.status == ExecutionStatus.COMPLETED)
        
        execution_times = [r.total_execution_time for r in self.execution_history if r.status == ExecutionStatus.COMPLETED]
        avg_time = sum(execution_times) / len(execution_times) if execution_times else 0
        
        return {
            "total_executions": total,
            "successful_executions": successful,
            "success_rate": successful / total,
            "average_execution_time": avg_time,
            "recent_executions": [
                {
                    "workflow_id": r.workflow_id,
                    "goal": r.goal,
                    "status": r.status.value,
                    "execution_time": r.total_execution_time,
                    "node_count": len(r.node_results)
                }
                for r in self.execution_history[-5:]
            ]
        }


# Factory function
def get_evo_workflow_executor(llm_config: Dict[str, Any]) -> EvoWorkflowExecutor:
    """Get an EvoWorkflowExecutor instance."""
    return EvoWorkflowExecutor(llm_config)
