"""
Dynamic Consensus Generator - æ ¹æ®ç”Ÿæˆçš„ä»£ç åŠ¨æ€å½¢æˆä»£ç†å…±è¯†
"""

import ast
import re
import logging
from typing import Dict, List, Any, Optional
from datetime import datetime

logger = logging.getLogger(__name__)


class CodeAnalyzer:
    """åˆ†æä»£ç å¹¶æå–å…±è¯†è¦ç´ """
    
    def analyze_function_code(self, func_code: str, func_name: str, task_description: str) -> Dict[str, Any]:
        """
        åˆ†æå‡½æ•°ä»£ç ï¼Œæå–å…±è¯†è¦ç´ 
        
        Args:
            func_code: å‡½æ•°æºä»£ç 
            func_name: å‡½æ•°å
            task_description: ä»»åŠ¡æè¿°
            
        Returns:
            åŒ…å«å…±è¯†è¦ç´ çš„å­—å…¸
        """
        consensus_elements = {
            'naming_analysis': self._analyze_naming(func_name, task_description),
            'type_analysis': self._analyze_types(func_code),
            'error_handling_analysis': self._analyze_error_handling(func_code),
            'design_patterns': self._analyze_design_patterns(func_code),
            'system_constraints': self._identify_system_constraints(func_code, func_name),
            'code_complexity': self._analyze_complexity(func_code),
            'documentation_style': self._analyze_documentation(func_code)
        }
        
        return consensus_elements
    
    def _analyze_naming(self, func_name: str, task_description: str) -> Dict[str, Any]:
        """åˆ†æå‘½åæ¨¡å¼"""
        analysis = {}
        
        # æ£€æµ‹æ—¶é—´æˆ³/å“ˆå¸Œåç¼€
        timestamp_match = re.search(r'_(\d{10,})$', func_name)
        if timestamp_match:
            timestamp = timestamp_match.group(1)
            analysis['has_timestamp_suffix'] = True
            analysis['timestamp_value'] = timestamp
            analysis['timestamp_purpose'] = "ç”¨äºå‡½æ•°ç‰ˆæœ¬æ§åˆ¶å’Œå”¯ä¸€æ€§æ ‡è¯†"
            analysis['base_name'] = func_name.replace(f'_{timestamp}', '')
        else:
            analysis['has_timestamp_suffix'] = False
            analysis['base_name'] = func_name
        
        # åˆ†æå‘½åé£æ ¼
        if func_name.startswith('create_a_'):
            analysis['naming_style'] = 'descriptive_creation'
            analysis['style_rationale'] = 'ç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆçš„æè¿°æ€§åˆ›å»ºå‡½æ•°å'
        elif '_' in func_name:
            analysis['naming_style'] = 'snake_case'
        else:
            analysis['naming_style'] = 'other'
        
        # åˆ†æåç§°é•¿åº¦
        analysis['name_length'] = len(func_name)
        analysis['is_long_name'] = len(func_name) > 30
        
        return analysis
    
    def _analyze_types(self, func_code: str) -> Dict[str, Any]:
        """åˆ†æç±»å‹æ³¨è§£"""
        analysis = {}
        
        try:
            tree = ast.parse(func_code)
            func_def = tree.body[0] if tree.body and isinstance(tree.body[0], ast.FunctionDef) else None
            
            if func_def:
                # åˆ†æè¿”å›ç±»å‹
                if func_def.returns:
                    return_type = ast.unparse(func_def.returns) if hasattr(ast, 'unparse') else str(func_def.returns)
                    analysis['return_type'] = return_type.lower()
                    analysis['uses_any_return'] = 'any' in return_type.lower()
                    
                    if analysis['uses_any_return']:
                        analysis['any_usage_context'] = 'ç³»ç»Ÿè¦æ±‚ä½¿ç”¨Anyç±»å‹ä»¥ä¿æŒæœ€å¤§çµæ´»æ€§'
                
                # åˆ†æå‚æ•°ç±»å‹
                analysis['parameter_types'] = []
                for arg in func_def.args.args:
                    if arg.annotation:
                        param_type = ast.unparse(arg.annotation) if hasattr(ast, 'unparse') else str(arg.annotation)
                        analysis['parameter_types'].append({
                            'name': arg.arg,
                            'type': param_type
                        })
        except Exception as e:
            logger.warning(f"ç±»å‹åˆ†æå¤±è´¥: {e}")
            analysis['analysis_error'] = str(e)
        
        return analysis
    
    def _analyze_error_handling(self, func_code: str) -> Dict[str, Any]:
        """åˆ†æé”™è¯¯å¤„ç†æ¨¡å¼"""
        analysis = {}
        
        # æ£€æµ‹try-exceptå—
        has_try_except = 'try:' in func_code and 'except' in func_code
        analysis['has_exception_handling'] = has_try_except
        
        if has_try_except:
            # æ£€æµ‹å¼‚å¸¸ç±»å‹
            if 'except Exception' in func_code:
                analysis['exception_scope'] = 'broad'
                analysis['exception_critique'] = 'æ•è·æ‰€æœ‰å¼‚å¸¸å¯èƒ½æ©ç›–çœŸæ­£çš„é—®é¢˜'
            elif 'except ' in func_code:
                analysis['exception_scope'] = 'specific'
                analysis['exception_critique'] = 'ä½¿ç”¨äº†ç‰¹å®šå¼‚å¸¸ç±»å‹ï¼Œè¿™æ˜¯å¥½çš„å®è·µ'
            
            # æ£€æµ‹é”™è¯¯å¤„ç†ç­–ç•¥
            if 'return ""' in func_code or 'return None' in func_code:
                analysis['error_strategy'] = 'silent_fallback'
                analysis['strategy_critique'] = 'é™é»˜å¤±è´¥å¯èƒ½è®©ç”¨æˆ·éš¾ä»¥å‘ç°é—®é¢˜'
            elif 'raise' in func_code:
                analysis['error_strategy'] = 'exception_propagation'
                analysis['strategy_critique'] = 'å¼‚å¸¸ä¼ æ’­è®©è°ƒç”¨è€…å¯ä»¥è‡ªè¡Œå¤„ç†é”™è¯¯'
        
        # æ£€æµ‹Noneå¤„ç†
        if 'is None' in func_code:
            analysis['handles_none_input'] = True
            if 'return ""' in func_code:
                analysis['none_handling_strategy'] = 'convert_to_empty'
                analysis['none_critique'] = 'Noneè½¬æ¢ä¸ºç©ºå€¼å¯èƒ½æ©ç›–é€»è¾‘é”™è¯¯'
            elif 'raise' in func_code:
                analysis['none_handling_strategy'] = 'raise_exception'
                analysis['none_critique'] = 'å¯¹NoneæŠ›å‡ºå¼‚å¸¸ç¬¦åˆPythonæƒ¯ä¾‹'
        
        return analysis
    
    def _analyze_design_patterns(self, func_code: str) -> Dict[str, Any]:
        """åˆ†æè®¾è®¡æ¨¡å¼"""
        analysis = {}
        
        # æ£€æµ‹å‡½æ•°å¤æ‚åº¦
        line_count = len([line for line in func_code.split('\n') if line.strip()])
        analysis['line_count'] = line_count
        analysis['complexity_level'] = 'simple' if line_count < 20 else 'complex'
        
        # æ£€æµ‹å•ä¸€èŒè´£
        operation_count = 0
        if 'return' in func_code:
            operation_count += func_code.count('return')
        if 'if' in func_code:
            operation_count += func_code.count('if')
        
        analysis['operation_count'] = operation_count
        analysis['follows_srp'] = operation_count <= 3  # ç®€å•å¯å‘å¼
        
        return analysis
    
    def _identify_system_constraints(self, func_code: str, func_name: str) -> Dict[str, Any]:
        """è¯†åˆ«ç³»ç»Ÿçº¦æŸ"""
        constraints = {}
        
        # è‡ªåŠ¨ç”Ÿæˆçš„å‡½æ•°ç‰¹å¾
        if re.search(r'_\d{10,}$', func_name):
            constraints['auto_generated'] = True
            constraints['naming_constraint'] = 'ç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆå¸¦æ—¶é—´æˆ³çš„å‡½æ•°åä»¥ç¡®ä¿å”¯ä¸€æ€§'
        
        # è¿”å›ç±»å‹çº¦æŸ
        if '-> any' in func_code.lower() or '-> Any' in func_code:
            constraints['return_type_constraint'] = True
            constraints['return_type_rationale'] = 'ç³»ç»Ÿè¦æ±‚è¿”å›Anyç±»å‹ä»¥æ”¯æŒå¤šç§è¿”å›å€¼ç±»å‹'
        
        # å®‰å…¨çº¦æŸ
        dangerous_patterns = ['import os', 'import sys', 'open(', 'exec(', 'eval(']
        has_dangerous = any(pattern in func_code for pattern in dangerous_patterns)
        constraints['security_constrained'] = not has_dangerous
        
        return constraints
    
    def _analyze_complexity(self, func_code: str) -> Dict[str, Any]:
        """åˆ†æä»£ç å¤æ‚åº¦"""
        analysis = {}
        
        # ç®€å•çš„å¤æ‚åº¦æŒ‡æ ‡
        analysis['total_lines'] = len(func_code.split('\n'))
        analysis['code_lines'] = len([line for line in func_code.split('\n') if line.strip() and not line.strip().startswith('#')])
        analysis['comment_lines'] = len([line for line in func_code.split('\n') if line.strip().startswith('#')])
        
        # æ§åˆ¶æµå¤æ‚åº¦
        control_keywords = ['if', 'elif', 'else', 'for', 'while', 'try', 'except', 'finally']
        analysis['control_flow_count'] = sum(func_code.count(keyword) for keyword in control_keywords)
        
        return analysis
    
    def _analyze_documentation(self, func_code: str) -> Dict[str, Any]:
        """åˆ†ææ–‡æ¡£é£æ ¼"""
        analysis = {}
        
        # æ£€æµ‹docstring
        has_docstring = '"""' in func_code or "'''" in func_code
        analysis['has_docstring'] = has_docstring
        
        if has_docstring:
            # æå–docstringå†…å®¹
            docstring_match = re.search(r'"""(.*?)"""', func_code, re.DOTALL)
            if docstring_match:
                docstring = docstring_match.group(1).strip()
                analysis['docstring_length'] = len(docstring)
                analysis['has_parameters_section'] = 'Parameters:' in docstring or 'Args:' in docstring
                analysis['has_returns_section'] = 'Returns:' in docstring
                analysis['has_examples_section'] = 'Examples:' in docstring or 'Example:' in docstring
        
        return analysis


class DynamicConsensusGenerator:
    """åŠ¨æ€ç”Ÿæˆä»£ç†å…±è¯†"""
    
    def __init__(self):
        self.analyzer = CodeAnalyzer()
    
    def generate_consensus(self, func_code: str, func_name: str, task_description: str) -> Dict[str, Any]:
        """
        æ ¹æ®ç”Ÿæˆçš„ä»£ç åŠ¨æ€ç”Ÿæˆå…±è¯†
        
        Args:
            func_code: å‡½æ•°æºä»£ç 
            func_name: å‡½æ•°å
            task_description: ä»»åŠ¡æè¿°
            
        Returns:
            åŠ¨æ€ç”Ÿæˆçš„å…±è¯†å­—å…¸
        """
        logger.info(f"ä¸ºå‡½æ•° {func_name} ç”ŸæˆåŠ¨æ€å…±è¯†")
        
        # åˆ†æä»£ç 
        analysis = self.analyzer.analyze_function_code(func_code, func_name, task_description)
        
        # ç”Ÿæˆå…±è¯†
        consensus = {
            'context_info': {
                'function_name': func_name,
                'task_description': task_description,
                'analysis_timestamp': datetime.now().isoformat()
            },
            'technical_consensus': self._build_technical_consensus(analysis),
            'system_constraints': self._build_system_constraints(analysis),
            'design_principles': self._build_design_principles(analysis),
            'dialogue_guidelines': self._build_dialogue_guidelines(analysis)
        }
        
        return consensus
    
    def _build_technical_consensus(self, analysis: Dict[str, Any]) -> Dict[str, Any]:
        """æ„å»ºæŠ€æœ¯å…±è¯†"""
        consensus = {}
        
        # å‘½åå…±è¯†
        naming = analysis.get('naming_analysis', {})
        if naming.get('has_timestamp_suffix'):
            consensus['function_naming'] = {
                'timestamp_suffix': {
                    'purpose': naming.get('timestamp_purpose', 'ç”¨äºç‰ˆæœ¬æ§åˆ¶å’Œå”¯ä¸€æ€§'),
                    'value': naming.get('timestamp_value'),
                    'rationale': 'ç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆï¼Œé˜²æ­¢å‘½åå†²çªå¹¶æ”¯æŒå‡½æ•°æ¼”è¿›è·Ÿè¸ª'
                }
            }
        
        # ç±»å‹å…±è¯†
        type_analysis = analysis.get('type_analysis', {})
        if type_analysis.get('uses_any_return'):
            consensus['type_annotations'] = {
                'any_return_type': {
                    'context': type_analysis.get('any_usage_context', 'ç³»ç»Ÿè¦æ±‚'),
                    'rationale': 'ä¿æŒæœ€å¤§çµæ´»æ€§ï¼Œæ”¯æŒå¤šç§è¿”å›å€¼ç±»å‹',
                    'alternatives': 'åœ¨æ˜ç¡®è¿”å›ç±»å‹æ—¶å¯è€ƒè™‘ä½¿ç”¨Unionç±»å‹'
                }
            }
        
        return consensus
    
    def _build_system_constraints(self, analysis: Dict[str, Any]) -> Dict[str, Any]:
        """æ„å»ºç³»ç»Ÿçº¦æŸ"""
        constraints = analysis.get('system_constraints', {})
        
        system_constraints = {}
        
        if constraints.get('auto_generated'):
            system_constraints['auto_generation'] = {
                'naming_pattern': constraints.get('naming_constraint', 'è‡ªåŠ¨ç”Ÿæˆå‘½å'),
                'uniqueness_guarantee': 'æ—¶é—´æˆ³åç¼€ç¡®ä¿å‡½æ•°åå”¯ä¸€æ€§',
                'evolution_support': 'æ”¯æŒå‡½æ•°ç‰ˆæœ¬æ¼”è¿›å’Œè¿½è¸ª'
            }
        
        if constraints.get('return_type_constraint'):
            system_constraints['type_flexibility'] = {
                'return_type_policy': constraints.get('return_type_rationale', 'çµæ´»è¿”å›ç±»å‹'),
                'type_safety_balance': 'åœ¨ç±»å‹å®‰å…¨å’Œçµæ´»æ€§ä¹‹é—´å–å¾—å¹³è¡¡'
            }
        
        return system_constraints
    
    def _build_design_principles(self, analysis: Dict[str, Any]) -> Dict[str, Any]:
        """æ„å»ºè®¾è®¡åŸåˆ™"""
        principles = {}
        
        # é”™è¯¯å¤„ç†åŸåˆ™
        error_analysis = analysis.get('error_handling_analysis', {})
        if error_analysis.get('has_exception_handling'):
            principles['error_handling'] = {
                'current_strategy': error_analysis.get('error_strategy', 'unknown'),
                'critique': error_analysis.get('strategy_critique', ''),
                'improvement_direction': self._suggest_error_handling_improvement(error_analysis)
            }
        
        # å¤æ‚åº¦åŸåˆ™
        complexity = analysis.get('code_complexity', {})
        principles['complexity_management'] = {
            'current_level': 'simple' if complexity.get('code_lines', 0) < 20 else 'complex',
            'line_count': complexity.get('code_lines', 0),
            'maintainability_focus': 'ä¿æŒä»£ç ç®€æ´å’Œå¯è¯»æ€§'
        }
        
        return principles
    
    def _build_dialogue_guidelines(self, analysis: Dict[str, Any]) -> Dict[str, Any]:
        """æ„å»ºå¯¹è¯æŒ‡å¯¼åŸåˆ™"""
        guidelines = {
            'context_awareness': {
                'acknowledge_constraints': 'ç†è§£å¹¶æ‰¿è®¤ç³»ç»Ÿçº¦æŸå’Œè®¾è®¡èƒŒæ™¯',
                'focus_on_improvements': 'ä¸“æ³¨äºåœ¨çº¦æŸæ¡ä»¶ä¸‹çš„æ”¹è¿›æœºä¼š',
                'avoid_invalid_criticism': 'é¿å…å¯¹ç³»ç»Ÿè®¾è®¡å†³ç­–çš„æ— æ•ˆæ‰¹è¯„'
            },
            'constructive_approach': {
                'build_on_analysis': 'åŸºäºä»£ç åˆ†æç»“æœè¿›è¡Œè®¨è®º',
                'suggest_alternatives': 'åœ¨æ‰¿è®¤çº¦æŸçš„å‰æä¸‹æå‡ºæ›¿ä»£æ–¹æ¡ˆ',
                'consider_tradeoffs': 'è€ƒè™‘ä¸åŒæ–¹æ¡ˆçš„æƒè¡¡å’Œå–èˆ'
            }
        }
        
        # æ ¹æ®å…·ä½“åˆ†ææ·»åŠ ç‰¹å®šæŒ‡å¯¼
        naming = analysis.get('naming_analysis', {})
        if naming.get('is_long_name'):
            guidelines['specific_guidance'] = {
                'naming_discussion': 'è®¨è®ºé•¿å‡½æ•°åçš„å¯è¯»æ€§å½±å“ï¼Œä½†è¦ç†è§£å…¶å¿…è¦æ€§',
                'user_experience_focus': 'è€ƒè™‘å¦‚ä½•åœ¨ä¿æŒç³»ç»Ÿçº¦æŸçš„åŒæ—¶æ”¹å–„ç”¨æˆ·ä½“éªŒ'
            }
        
        return guidelines
    
    def _suggest_error_handling_improvement(self, error_analysis: Dict[str, Any]) -> str:
        """å»ºè®®é”™è¯¯å¤„ç†æ”¹è¿›æ–¹å‘"""
        if error_analysis.get('exception_scope') == 'broad':
            return 'è€ƒè™‘ä½¿ç”¨æ›´å…·ä½“çš„å¼‚å¸¸ç±»å‹ï¼Œæˆ–è¯„ä¼°æ˜¯å¦çœŸçš„éœ€è¦å¼‚å¸¸å¤„ç†'
        elif error_analysis.get('error_strategy') == 'silent_fallback':
            return 'è€ƒè™‘æ˜¯å¦åº”è¯¥è®©å¼‚å¸¸ä¼ æ’­ï¼Œè®©è°ƒç”¨è€…å†³å®šå¦‚ä½•å¤„ç†'
        else:
            return 'å½“å‰é”™è¯¯å¤„ç†ç­–ç•¥åˆç†ï¼Œå¯è€ƒè™‘åœ¨æ–‡æ¡£ä¸­è¯´æ˜'
    
    def format_consensus_for_dialogue(self, consensus: Dict[str, Any]) -> str:
        """æ ¼å¼åŒ–å…±è¯†ä¿¡æ¯ç”¨äºå¯¹è¯"""
        formatted = "**ğŸ¯ åŸºäºå½“å‰ä»£ç çš„æŠ€æœ¯å…±è¯†ï¼š**\n\n"
        
        # ä¸Šä¸‹æ–‡ä¿¡æ¯
        context = consensus.get('context_info', {})
        formatted += f"**ğŸ“‹ åˆ†æå¯¹è±¡**: {context.get('function_name', 'unknown')}\n"
        formatted += f"**ğŸ“ ä»»åŠ¡æè¿°**: {context.get('task_description', 'unknown')}\n\n"
        
        # æŠ€æœ¯å…±è¯†
        tech_consensus = consensus.get('technical_consensus', {})
        
        # å‡½æ•°å‘½åå…±è¯†
        if 'function_naming' in tech_consensus:
            naming = tech_consensus['function_naming']
            if 'timestamp_suffix' in naming:
                suffix_info = naming['timestamp_suffix']
                formatted += f"**ğŸ·ï¸ å‡½æ•°å‘½å**: {suffix_info.get('rationale', 'ç³»ç»Ÿå‘½åç­–ç•¥')}\n"
                formatted += f"   - æ—¶é—´æˆ³å€¼: {suffix_info.get('value', 'N/A')}\n"
                formatted += f"   - ç›®çš„: {suffix_info.get('purpose', 'å”¯ä¸€æ€§ä¿è¯')}\n\n"
        
        # ç±»å‹æ³¨è§£å…±è¯†
        if 'type_annotations' in tech_consensus:
            types = tech_consensus['type_annotations']
            if 'any_return_type' in types:
                any_info = types['any_return_type']
                formatted += f"**ğŸ”§ è¿”å›ç±»å‹Any**: {any_info.get('rationale', 'ç³»ç»Ÿè¦æ±‚')}\n"
                formatted += f"   - èƒŒæ™¯: {any_info.get('context', 'çµæ´»æ€§éœ€æ±‚')}\n"
                formatted += f"   - æ›¿ä»£æ–¹æ¡ˆ: {any_info.get('alternatives', 'è€ƒè™‘å…·ä½“ç±»å‹')}\n\n"
        
        # ç³»ç»Ÿçº¦æŸ
        constraints = consensus.get('system_constraints', {})
        if constraints:
            formatted += "**âš™ï¸ ç³»ç»Ÿçº¦æŸç†è§£**:\n"
            for key, value in constraints.items():
                if isinstance(value, dict):
                    formatted += f"   - {key}: {value.get('naming_pattern', value.get('return_type_policy', 'ç³»ç»Ÿç­–ç•¥'))}\n"
        
        formatted += "\n**ğŸ’¡ è¯·åŸºäºä»¥ä¸Šå…±è¯†è¿›è¡Œå»ºè®¾æ€§è®¨è®ºï¼Œä¸“æ³¨äºåœ¨çº¦æŸæ¡ä»¶ä¸‹çš„æ”¹è¿›æœºä¼šï¼**\n\n"
        
        return formatted
